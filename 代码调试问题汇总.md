---

---

#### 1.开始训练到非冻结代时，爆显卡

RuntimeError: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 7.79 GiB total capacity; 6.37 GiB already allocated; 10.06 MiB free; 6.45 GiB reserved in total by PyTorch)

目前8G的Gpu batch_size为8  为16时候不冻结网络会溢出

#### 2.模块导入问题

- pycharm具有重构机制，移动某个模块.py 会导致引用该模块的文件的import路径 也不是所有的重构都可以 有些时候需要局部修改
- 再pycharm等ide上运行，编辑器帮我们配置好了路径，一般是从项目root为起始import 

![Screenshot from 2021-01-21 16-49-31](/home/sta/Desktop/guo/yolo3-pytorch-master/.asset/Screenshot from 2021-01-21 16-49-31.png)

- 在终端运行脚本报错是因为，找不到内部引用的文件，特别是自己写的模块，要在运行的脚本开始加入声明，sys.path.append("../") 				

#### 3.训练模型优化

##### 1.问题汇总

[模型训练心得]: https://blog.csdn.net/orangefly0214/article/details/81032036

`问题现象1：`
纯已有的伪数据预测结果的mAP结果很好，但预测实际物体时误差很大，误差随物体种类特征不同而不同，后续增加背景和主体后效果还不是很明显；

`猜测原因2：`
纯增加数据量，背景，主体改善不是很大 ，loss的损失率都接近6，测试集的map都是很高，说明模型很好了，重点也不是调参问题，而是用虚拟    物体预测实际场景的物体还是出入很大。

`优化方法3：`
1.修改伪数据里面风扇的旋转问题、体重秤的视角问题    2.自己标注实际场景的数据，排查原因先采取单一数据的优化(鞋)，先采集实际主体的半伪数据，再全真数据（控制变量法）。  3.自动化数据脚本的优化：2*2  数据透视特征 refactor易于扩展

##### 2.调试记录

| 测试模型                                                     | 测试效果评估               | 原因                                                       | map  |
| ------------------------------------------------------------ | -------------------------- | ---------------------------------------------------------- | ---- |
| 1.12  500张                                                  | 无框                       | 预模型加载问题？                                           |      |
| 1.24 15张背景 10+张主体   3000+                              | 体重秤误判、风扇检查效果差 |                                                            |      |
| 2021_01_26-12_17模型  增加主体50+ 及背景40+ lr_first = 1e-2  3200 | 整体有些提升 效果有限      | 调整方向该为数据集制作，而不是修改超参数，loss一个数量级。 | 98%  |
| 2021_01_28-08_59模型 3200 100itera 【2，3，4】  8batch  1e-3 | 鞋、线、屎、碗提升         | 丰富主体尺寸                                               |      |
| 2021_01_28-16_07模型 1600 100itera 【2，3，4】  8batch  1e-3   数据风扇正立 | 风扇检测提升               | 大部分为直立数据                                           |      |

##### 3.调参认知总结：

- 自己的loss和标准数据集是一个数量级的化就能排除超参数的原因。
- 数据集的背景影响不大，主要还是主体psd视角尽量符合机器人视角，在实际拍摄检测的时候才有可靠性，然而刚开始网上扣取的图片是按照人类视角拍摄，导致准确率不是很高，后续分析问题要从这个角度思考，尽量保证数据集和实际拍摄场景一致。（用相机俯视拍摄，准确率很高）
- 分析各类情况：鞋、线、屎、碗基本满足 袜子和抹布容易误判  体重秤问题严重  风扇放正不能检测。

#### 4.配套知识点

**总结nms的流程**
 每一个image,会预测出N个detetction信息,包括4+1+C(4个坐标信息,1个obj_score以及C个class_probability)

- 首先过滤掉obj_score < confidence的行      
- 每一行只取class_probability最高的作为预测出来的类别
- 将所有的预测按照obj_score从大到小排序
- 循环每一种类别,开始做nms
  - 比较第一个box与其后所有box的iou,删除iou>threshold的box,即剔除所有相似box
  - 比较下一个box与其后所有box的iou,删除所有与该box相似的box
  - 不断重复上述过程,直至不再有相似box
  - 至此,实现了当前处理的类别的多个box均是独一无二的box.
